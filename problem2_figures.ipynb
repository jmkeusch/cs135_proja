{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme('notebook', style='whitegrid', font_scale=1.25)\n",
    "\n",
    "# autoload changes in other files, so you don't have to restart the Jupyter kernel each time you make a change to the imported code.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimentloop2 import load_data, grid_search, PARAM_GRID, pipeline\n",
    "from preprocessing import text_col, num_del, num_to_sp\n",
    "from sklearn.pipeline import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_NC, y_N = load_data()\n",
    "param_grid = {\n",
    "    \"featurize__review_bow__token_pattern\": [\n",
    "        r\"(?u)\\b\\w+\\b\",\n",
    "        r\"(?u)\\b\\w\\w+\\b\",\n",
    "        r\"(?u)\\b\\w\\w\\w+\\b\",\n",
    "        # r\"(?u)\\b\\w\\w\\w\\w+\\b\",\n",
    "    ],\n",
    "    \"featurize__review_bow__strip_accents\": [\"unicode\", None],\n",
    "    \"featurize__review_bow__lowercase\": [True, False],\n",
    "    \"featurize__review_bow__min_df\": [1, 2, 3],\n",
    "    \"featurize__review_bow__max_df\": np.logspace(-2, 0, 11),\n",
    "    #\"classify__C\": np.logspace(-5, 4, 19),\n",
    "    \"classify__C\": np.logspace(-2, 2, 5),\n",
    "}\n",
    "search = grid_search(x_NC, y_N, param_grid, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best auroc:  0.8875034722222221\n",
      "vocab size:  4526\n",
      "best params:  {'classify__C': 10.0, 'featurize__review_bow__lowercase': True, 'featurize__review_bow__max_df': 0.15848931924611143, 'featurize__review_bow__min_df': 1, 'featurize__review_bow__strip_accents': None, 'featurize__review_bow__token_pattern': '(?u)\\\\b\\\\w+\\\\b'}\n"
     ]
    }
   ],
   "source": [
    "print(\"best auroc: \", search.best_score_)\n",
    "print(\"vocab size: \", len(search.best_estimator_.named_steps[\"featurize\"].named_transformers_['review_bow'].vocabulary_))\n",
    "print(\"best params: \", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_l2 = {k: [v] for k, v in search.best_params_.items()}\n",
    "param_grid_l2['classify__C'] = np.logspace(-5, 4, 19)\n",
    "search_l2 = grid_search(x_NC, y_N, param_grid_l2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best auroc:  0.8879791666666665\n",
      "vocab size:  4526\n",
      "best params:  {'classify__C': 3.1622776601683795, 'featurize__review_bow__lowercase': True, 'featurize__review_bow__max_df': 0.15848931924611143, 'featurize__review_bow__min_df': 1, 'featurize__review_bow__strip_accents': None, 'featurize__review_bow__token_pattern': '(?u)\\\\b\\\\w+\\\\b'}\n"
     ]
    }
   ],
   "source": [
    "print(\"best auroc: \", search_l2.best_score_)\n",
    "print(\"vocab size: \", len(search_l2.best_estimator_.named_steps[\"featurize\"].named_transformers_['review_bow'].vocabulary_))\n",
    "print(\"best params: \", search_l2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theo/opt/miniconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/theo/opt/miniconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid_l1 = {k: [v] for k, v in search.best_params_.items()}\n",
    "param_grid_l1[\"classify__penalty\"] = ['l1']\n",
    "param_grid_l1[\"classify__C\"] = np.logspace(-3, 3, 15)\n",
    "param_grid_l1[\"classify__solver\"] = ['liblinear']\n",
    "search_l1 = grid_search(x_NC, y_N, param_grid_l1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best auroc:  0.8798020833333332\n",
      "vocab size:  4526\n",
      "best params:  {'classify__C': 2.6826957952797246, 'classify__penalty': 'l1', 'classify__solver': 'liblinear', 'featurize__review_bow__lowercase': True, 'featurize__review_bow__max_df': 0.15848931924611143, 'featurize__review_bow__min_df': 1, 'featurize__review_bow__strip_accents': None, 'featurize__review_bow__token_pattern': '(?u)\\\\b\\\\w+\\\\b'}\n"
     ]
    }
   ],
   "source": [
    "print(\"best auroc: \", search_l1.best_score_)\n",
    "print(\"vocab size: \", len(search_l1.best_estimator_.named_steps[\"featurize\"].named_transformers_['review_bow'].vocabulary_))\n",
    "print(\"best params: \", search_l1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 217)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_fp = 0\n",
    "cv_fn = 0\n",
    "best_param = search_l2.best_params_\n",
    "errs = pd.DataFrame().reindex(columns=x_NC.columns)\n",
    "#predictions = pd.DataFrame().reindex(columns=y_N).rename({'is_positive_sentiment': 'predicted_sentiment_positive'})\n",
    "for tix, vix in StratifiedKFold(n_splits=5).split(x_NC, y_N):\n",
    "    p = pipeline()\n",
    "    p.set_params(**best_param)\n",
    "    x_train_NC = x_NC.iloc[tix]\n",
    "    x_val_MC = x_NC.iloc[vix].copy()\n",
    "    p.fit(x_train_NC, y_N.iloc[tix])\n",
    "    yhat_val = p.predict(x_val_MC)\n",
    "    y_val = y_N.iloc[vix]\n",
    "    cv_fp += np.sum((yhat_val == 1) & (y_val == 0))\n",
    "    cv_fn += np.sum((yhat_val == 0) & (y_val == 1))\n",
    "    x_val_MC['true_sentiment_positive'] = y_val\n",
    "    x_val_MC['predicted_sentiment_positive'] = yhat_val\n",
    "    fold_errs = x_val_MC.where(yhat_val != y_val).dropna()\n",
    "    errs = pd.concat((errs, fold_errs))\n",
    "errs = errs.astype({'true_sentiment_positive': int, 'predicted_sentiment_positive': int})\n",
    "(cv_fp, cv_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs.to_csv('./problem2_best_cv_errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_test_roc_auc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# first line: data points along C values for train performance\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# second line: data points along C values for mean validation performance\u001b[39;00m\n\u001b[1;32m      4\u001b[0m c_grid_log \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(PARAM_GRID[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassify__C\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m val_performance \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_results_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_test_roc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m train_performance \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_train_roc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m val_all_folds_performance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose([search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_test_roc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_test_roc_auc'"
     ]
    }
   ],
   "source": [
    "# first line: data points along C values for train performance\n",
    "# second line: data points along C values for mean validation performance\n",
    "\n",
    "c_grid_log = np.log10(PARAM_GRID['classify__C'])\n",
    "val_performance = search.cv_results_['mean_test_roc_auc']\n",
    "train_performance = search.cv_results_['mean_train_roc_auc']\n",
    "\n",
    "val_all_folds_performance = np.transpose([search.cv_results_[f'split{k}_test_roc_auc'] for k in range(5)])\n",
    "train_all_folds_performance = np.transpose([search.cv_results_[f'split{k}_train_roc_auc'] for k in range(5)])\n",
    "\n",
    "# TODO: make legend explicit so we can avoid duplicate labels\n",
    "plt.title('C-Grid Hyperparameter Search')\n",
    "plt.plot(c_grid_log, val_performance, 'r-', label='validation mean')\n",
    "plt.plot(c_grid_log, val_all_folds_performance, 'r.', label='validation fold')\n",
    "plt.plot(c_grid_log, train_performance, 'b-', label='training mean')\n",
    "plt.plot(c_grid_log, train_all_folds_performance, 'b.', label='train fold')\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(1.5, 0.5))\n",
    "\n",
    "plt.ylabel('AUROC')\n",
    "plt.xlabel('$\\log_{10} C$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
